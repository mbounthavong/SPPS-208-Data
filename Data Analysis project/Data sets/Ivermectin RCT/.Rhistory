n_pat     <- 550                   # cohort size
n_years   <- 60                    # number of years
generate <- gen_data(n_pat,n_years) # generates true, censored and OS/PFS data
true_data <- generate$true_data
sim_data <- generate$sim_data
status   <- generate$status
OS_PFS_data <- generate$OS_PFS_data
head(OS_PFS_data)
colnames(IPD) <- c("time", "status")
dim(IPD)
IPD
colnames(IPD) <- c("time", "status", "censor")
head(IPD)
fit.pfs <- fit.fun(time = "time", status = "status", data = IPD, times = IPD[,1], extrapolate = TRUE)
head(OS_PFS_data)
?plot.flexsurvreg
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.97, 1))
plot(we, xlim = c(0, 60), ylim = c(0.97, 1))           ### Weibull
plot.flexsurvreg(we)
lines(we, xlim = c(0, 60), ylim = c(0.97, 1))
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.97, 1))
lines(we, xlim = c(0, 60), ylim = c(0.97, 1), extrapolate = T)
plot(we, xlim = c(0, 60), ylim = c(0.97, 1), extrapolate = TRUE)           ### Weibull
plot(we, xlim = c(0, 60), ylim = c(0.97, 1))           ### Weibull
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.97, 1))
plot(we, xlim = c(0, 60), ylim = c(0.97, 1))           ### Weibull
plot.flexsurvreg
?plot.flexsurvreg
summary(we)
plot(we, t = time)
plot(we, time = 60, ylim = c(0.97, 1))           ### Weibull
plot(we, t = 60, ylim = c(0.97, 1))           ### Weibull
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.97, 1))
plot(we, t = 60, ylim = c(0.97, 1))           ### Weibull
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.97, 1))
lines.flexsurvreg(we)
?lines.flexsurvreg
lines(we, t = 60, ylim = c(0.97, 1), extrapolate = T)
lines(we, t = times, ylim = c(0.97, 1), extrapolate = T)
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.0, 1))
lines(we, t = times, ylim = c(0.00, 1), extrapolate = T)
summary(we)
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.0, 1))
lines(we, t = times, ylim = c(0.00, 1))
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 60), ylim = c(0.0, 1))
lines(we, t = time, ylim = c(0.00, 1))
lines(we, t = times, ylim = c(0.00, 1))
times
times <- seq(0, 60, 0.5)
times
lines(we, t = times, ylim = c(0.00, 1))
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 120), ylim = c(0.0, 1))
times <- seq(0, 120, 0.5)
lines(we, t = times, ylim = c(0.00, 1))
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 120), ylim = c(0.80, 1))
times <- seq(0, 120, 0.5)
lines(we, t = times, ylim = c(0.80, 1))
12*60
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 720), ylim = c(0.00, 1))
times <- seq(0, 720, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1))
80*12
### Plotting long-term, out to 120 months
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1))
### Plotting long-term, out to 120 months
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), lcol = "blue")
lines(we, t = times, ylim = c(0.00, 1), color = "blue")
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue")
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue")
lines(ex, t = times, ylim = c(0.00, 1), col = "red")
lines(gegamma, t = times, ylim = c(0.00, 1), col = "green")
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green")
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma"), lty = 1, col = c("blue", "red", "green"))
ln <- flexsurvreg(Surv(IPD[,1], IPD[,2])~1, dist="lognormal")
ln
### Plotting long-term, out to 120 months
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
lines(ln, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma", "Log-norm"), lty = 1, col = c("blue", "red", "green", "purple"))
gompertz <- flexsurvreg(Surv(IPD[,1], IPD[,2])~1, dist="Gompertz")
gompertz
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
lines(ln, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
lines(gompertz, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma", "Log-norm", "Gompoertz"), lty = 1, col = c("blue", "red", "green", "purple", "pink"))
### Plotting long-term, out to 120 months
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
lines(ln, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
lines(gompertz, t = times, ylim = c(0.00, 1), col = "pink", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma", "Log-norm", "Gompoertz"), lty = 1, col = c("blue", "red", "green", "purple", "pink"))
### Plotting long-term, out to 120 months
plot(survfit(Surv(IPD[,1], IPD[,2])~1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
lines(ln, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
lines(gompertz, t = times, ylim = c(0.00, 1), col = "pink", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma", "Log-norm", "Gompertz"), lty = 1, col = c("blue", "red", "green", "purple", "pink"))
###############################################
## LOAD DATA and FUNCTION INPUTS
###############################################
### Clear work environment
rm(list=ls())
### Load libraries
library("MASS")
library("splines")
library("survival")
library("flexsurv")
library("readr")
library("knitr")
### Load RAW data from the KM digitized extraction (I have uploaded this on my GitHub page)
data1 <- "https://raw.githubusercontent.com/mbounthavong/CUA_Academic_detailing_and_naloxone/main/KM_tierney3.csv"
### Read CSV file
km.data <- read_csv(data1)
km.data <- data.frame(km.data)
km.data
#Read in survival times read by digizeit
digizeit <- km.data
t.S < -digizeit[,1]
### Clear work environment
rm(list=ls())
### Load libraries
library("MASS")
library("splines")
library("survival")
library("flexsurv")
library("readr")
library("knitr")
### Load RAW data from the KM digitized extraction (I have uploaded this on my GitHub page)
data1 <- "https://raw.githubusercontent.com/mbounthavong/CUA_Academic_detailing_and_naloxone/main/KM_tierney3.csv"
### Read CSV file
km.data <- read_csv(data1)
km.data <- data.frame(km.data)
km.data
#Read in survival times read by digizeit
digizeit <- km.data
t.S < -digizeit[,1]
### Clear work environment
rm(list=ls())
### Load libraries
library("MASS")
library("splines")
library("survival")
library("flexsurv")
library("readr")
library("knitr")
### Load RAW data from the KM digitized extraction (I have uploaded this on my GitHub page)
data1 <- "https://raw.githubusercontent.com/mbounthavong/CUA_Academic_detailing_and_naloxone/main/KM_tierney3.csv"
### Read CSV file
km.data <- read_csv(data1)
km.data <- data.frame(km.data)
km.data
#Read in survival times read by digizeit
digizeit <- km.data
t.S <- digizeit[,1]
S <- digizeit[,2]
#Algorithm to create a raw dataset from DigizeIt readings from a Kaplan-Meier curve
tot.events <- "NA" #tot.events = total no. of events reported. If not reported, then tot.events="NA"
arm.id <- 1 #arm indicator
###############################################
### BEGIN GUYOT's FUNCTION
###############################################
#Read in published numbers at risk, n.risk, at time, t.risk, lower and upper
# indexes for time interval
t.risk <- seq(0, 13, by = 1)
lower <- purrr::map_dbl(t.risk,
function(x) min(which(t.S >= x)))
upper <- purrr::map_dbl(c(t.risk[-1], Inf),
function(x) max(which(t.S < x)))
### n.risk is manually inputted from Tierney's Excel calculation at timepoints:
### 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12 months
n.risk <- c(9386, 9382, 9367, 9355, 9342, 9333, 9321, 9308, 9294, 9278, 9261, 9255, 9250)
n.int <- length(n.risk)
n.t <- upper[n.int]
### Initialize vectors
arm <- rep(arm.id,n.risk[1])
n.censor <- rep(0,(n.int-1))
n.hat <- rep(n.risk[1]+1,n.t)
cen <- rep(0,n.t)
d <- rep(0,n.t)
KM.hat <- rep(1,n.t)
last.i <- rep(1,n.int)
sumdL <- 0
if (n.int > 1){
#Time intervals 1,...,(n.int-1)
for (i in 1:(n.int-1)){
#First approximation of no. censored on interval i
n.censor[i]<- round(n.risk[i]*S[lower[i+1]]/S[lower[i]]- n.risk[i+1])
#Adjust tot. no. censored until n.hat = n.risk at start of interval (i+1)
while((n.hat[lower[i+1]]>n.risk[i+1])||((n.hat[lower[i+1]]<n.risk[i+1])&&(n.censor[i]>0))){
if (n.censor[i]<=0){
cen[lower[i]:upper[i]]<-0
n.censor[i]<-0
}
if (n.censor[i]>0){
cen.t<-rep(0,n.censor[i])
for (j in 1:n.censor[i]){
cen.t[j]<- t.S[lower[i]] +
j*(t.S[lower[(i+1)]]-t.S[lower[i]])/(n.censor[i]+1)
}
#Distribute censored observations evenly over time. Find no. censored on each time interval.
cen[lower[i]:upper[i]]<-hist(cen.t,breaks=t.S[lower[i]:lower[(i+1)]],
plot=F)$counts
}
#Find no. events and no. at risk on each interval to agree with K-M estimates read from curves
n.hat[lower[i]]<-n.risk[i]
last<-last.i[i]
for (k in lower[i]:upper[i]){
if (i==1 & k==lower[i]){
d[k]<-0
KM.hat[k]<-1
}
else {
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
}
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
if (d[k] != 0) last<-k
}
n.censor[i]<- n.censor[i]+(n.hat[lower[i+1]]-n.risk[i+1])
}
if (n.hat[lower[i+1]]<n.risk[i+1]) n.risk[i+1]<-n.hat[lower[i+1]]
last.i[(i+1)]<-last
}
}
### Time interval n.int.
if (n.int>1){
#Assume same censor rate as average over previous time intervals.
n.censor[n.int]<- min(round(sum(n.censor[1:(n.int-1)])*(t.S[upper[n.int]]-
t.S[lower[n.int]])/(t.S[upper[(n.int-1)]]-t.S[lower[1]])), n.risk[n.int])
}
if (n.int==1){n.censor[n.int]<-0}
if (n.censor[n.int] <= 0){
cen[lower[n.int]:(upper[n.int]-1)]<-0
n.censor[n.int]<-0
}
if (n.censor[n.int]>0){
cen.t<-rep(0,n.censor[n.int])
for (j in 1:n.censor[n.int]){
cen.t[j]<- t.S[lower[n.int]] +
j*(t.S[upper[n.int]]-t.S[lower[n.int]])/(n.censor[n.int]+1)
}
cen[lower[n.int]:(upper[n.int]-1)]<-hist(cen.t,breaks=t.S[lower[n.int]:upper[n.int]],
plot=F)$counts
}
### Find no. events and no. at risk on each interval to agree with K-M estimates read from curves
n.hat[lower[n.int]]<-n.risk[n.int]
last<-last.i[n.int]
for (k in lower[n.int]:upper[n.int]){
if(KM.hat[last] !=0){
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))} else {d[k]<-0}
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
#No. at risk cannot be negative
if (n.hat[k+1] < 0) {
n.hat[k+1]<-0
cen[k]<-n.hat[k] - d[k]
}
if (d[k] != 0) last<-k
}
### If total no. of events reported, adjust no. censored so that total no. of events agrees.
if (tot.events != "NA"){
if (n.int>1){
sumdL<-sum(d[1:upper[(n.int-1)]])
#If total no. events already too big, then set events and censoring = 0 on all further time intervals
if (sumdL >= tot.events){
d[lower[n.int]:upper[n.int]]<- rep(0,(upper[n.int]-lower[n.int]+1))
cen[lower[n.int]:(upper[n.int]-1)]<- rep(0,(upper[n.int]-lower[n.int]))
n.hat[(lower[n.int]+1):(upper[n.int]+1)]<- rep(n.risk[n.int],(upper[n.int]+1-lower[n.int]))
}
}
### Otherwise adjust no. censored to give correct total no. events
if ((sumdL < tot.events)|| (n.int==1)){
sumd<-sum(d[1:upper[n.int]])
while ((sumd > tot.events)||((sumd< tot.events)&&(n.censor[n.int]>0))){
n.censor[n.int]<- n.censor[n.int] + (sumd - tot.events)
if (n.censor[n.int]<=0){
cen[lower[n.int]:(upper[n.int]-1)]<-0
n.censor[n.int]<-0
}
if (n.censor[n.int]>0){
cen.t<-rep(0,n.censor[n.int])
for (j in 1:n.censor[n.int]){
cen.t[j]<- t.S[lower[n.int]] +
j*(t.S[upper[n.int]]-t.S[lower[n.int]])/(n.censor[n.int]+1)
}
cen[lower[n.int]:(upper[n.int]-1)]<-hist(cen.t,breaks=t.S[lower[n.int]:upper[n.int]],
plot=F)$counts
}
n.hat[lower[n.int]]<-n.risk[n.int]
last<-last.i[n.int]
for (k in lower[n.int]:upper[n.int]){
d[k]<-round(n.hat[k]*(1-(S[k]/KM.hat[last])))
KM.hat[k]<-KM.hat[last]*(1-(d[k]/n.hat[k]))
if (k != upper[n.int]){
n.hat[k+1]<-n.hat[k]-d[k]-cen[k]
#No. at risk cannot be negative
if (n.hat[k+1] < 0) {
n.hat[k+1]<-0
cen[k]<-n.hat[k] - d[k]
}
}
if (d[k] != 0) last<-k
}
sumd<- sum(d[1:upper[n.int]])
}
}
}
### Write.table(matrix(c(t.S,n.hat[1:n.t],d,cen),ncol=4,byrow=F),paste(path,KMdatafile,sep=""),sep="\t")
############################
### Now form IPD ###
############################
### Initialize vectors
t.IPD <- rep(t.S[n.t],n.risk[1])
event.IPD <- rep(0,n.risk[1])
### Write event time and event indicator (=1) for each event, as separate row in t.IPD and event.IPD
k = 1
for (j in 1:n.t){
if(d[j]!=0){
t.IPD[k:(k+d[j]-1)]<- rep(t.S[j],d[j])
event.IPD[k:(k+d[j]-1)]<- rep(1,d[j])
k<-k+d[j]
}
}
### Write censor time and event indicator (=0) for each censor, as separate row in t.IPD and event.IPD
for (j in 1:(n.t-1)){
if(cen[j]!=0){
t.IPD[k:(k+cen[j]-1)]<- rep(((t.S[j]+t.S[j+1])/2),cen[j])
event.IPD[k:(k+cen[j]-1)]<- rep(0,cen[j])
k<-k+cen[j]
}
}
#Output Individual Patient Data (IPD)
IPD <- matrix(c(t.IPD, event.IPD, arm),ncol = 3, byrow = F)
IPD
########################################
## Curve fitting
########################################
### Exponential curve fit
ex <- flexsurvreg(Surv(IPD[, 1], IPD[, 2]) ~ 1, dist="exponential")
ex
### Generalized gamma curve fit
gengamma <- flexsurvreg(Surv(IPD[, 1], IPD[, 2]) ~ 1, dist="gengamma")
gengamma
### Weibull curve fit
## https://stats.stackexchange.com/questions/259625/meaning-of-weibull-scale-and-shape-from-flexsurvreg
we <- flexsurvreg(Surv(IPD[, 1], IPD[, 2]) ~ 1, dist="weibull")
we$coefficients   ### Use the negative "shape" (it is presented as a (+), but use the (-) value
exp(we$coefficients)
lambda <- we$res[2]
gamma <- we$res[1]
lambda
gamma
we
### Log-normal curve fit
ln <- flexsurvreg(Surv(IPD[, 1], IPD[, 2]) ~ 1, dist="lognormal")
ln
### Log-normal curve fit
gompertz <- flexsurvreg(Surv(IPD[, 1], IPD[, 2]) ~ 1, dist="Gompertz")
gompertz
### Plot KM curve and the other survival fits
plot(survfit(Surv(IPD[, 1], IPD[, 2]) ~ 1), ylim = c(0.97, 1))
plot(we, ylim = c(0.97, 1))           ### Weibull
plot(ex, ylim = c(0.97, 1))           ### Exponential
plot(gengamma, ylim = c(0.97, 1))     ### Generalized gamma
### Plotting long-term, out to 960 months
plot(survfit(Surv(IPD[, 1], IPD[, 2]) ~ 1), xlim = c(0, 960), ylim = c(0.00, 1))
times <- seq(0, 960, 0.5)     ### Add sequence of time
lines(we, t = times, ylim = c(0.00, 1), col = "blue", lwd.ci=0, lty.ci=0)
lines(ex, t = times, ylim = c(0.00, 1), col = "red", lwd.ci=0, lty.ci=0)
lines(gengamma, t = times, ylim = c(0.00, 1), col = "green", lwd.ci=0, lty.ci=0)
lines(ln, t = times, ylim = c(0.00, 1), col = "purple", lwd.ci=0, lty.ci=0)
lines(gompertz, t = times, ylim = c(0.00, 1), col = "pink", lwd.ci=0, lty.ci=0)
legend("topright", legend = c("Weibull", "Exponential", "Gen Gamma", "Log-norm", "Gompertz"), lty = 1, col = c("blue", "red", "green", "purple", "pink"))
install.packages("dampack")
rm(list = ls())
library("datasetes")
install.packages("datasetes")
version
install.packages("dataset")
library("dataset")
install.packages("datasets")
install.packages("datasets")
esoph
library("survival")
data1 <- veterans
data1 <- veteran
data1
data1 <- ToothGrowth
data1
?glm
glm(len ~ supp, family = gaussian, data = data1)
summary(model1)
model1 <- glm(len ~ supp, family = gaussian, data = data1)
summary(model1)
confint(model1)
#### Use the ToothGrowth dataset
data1 <- ToothGrowth
#### Run the linear regression model
model1 <- glm(len ~ supp, family = gaussian, data = data1)
#### View the summary results ofthe linear regression model
summary(model1)
#### View the 95% Confidence Intervals for the beta coefficients
confint(model1)
data1 <- ToothGrowth
mtcars
model2 <- glm(len ~ supp + dose, family = gaussian, data = data1)
summary(model2)
confint(model2)
data2
data1
9.27 + (-3.70)*1 + 9.76*1
9.27 + (-3.70)*0 + 9.76*1
15.33-19.03
9.27 + (-3.70)*1 + 9.76*2
9.27 + (-3.70)*0 + 9.76*2
25.09 - 27.79
#### View the summary results of the linear regression model
summary(model2)
#### View the 95% Confidence Intervals for the beta coefficients
confint(model2)
4872 + 2485
22/30
43.37 / 1000
# This tutorial will introduce students to multigroup comparisons using
# one-way Analysis of Variance (ANOVA)
## Clear environment
rm(list = ls())
setwd("C:\\Users\\mbounthavong\\Dropbox\\UCSD Folder\\Courses\\R training\\Data")
## Import file
diabetes.data <- read.csv("diabetes.csv", header = TRUE)
head(diabetes.data)
diabetes.data
describe(diabetes.data)
summary(diabetes.data)
describeBy(diabetes.data)
## Clear environment
rm(list = ls())
## Set the working directory
#### For Windows:
setwd("C:\\Users\\mbounthavong\\Dropbox\\UCSD Folder\\Courses\\R training\\Data")
## Import file
diabetes.data <- read.csv("diabetes.csv", header = TRUE)
head(diabetes.data)
diabetes.data
summary(diabetes.data)
describeBy(diabetes.da)
library("psych")
describeBy(diabetes.da)
rm(list = ls())
setwd("C:\\Users\\mbounthavong\\Dropbox\\UCSD Folder\\Courses\\SPPS 208\\Winter 2023\\Stats project\\Data sets\\Ivermectin RCT")
library("openxlsx")
setwd("Downloads")
rm(list = ls())
rm(list = ls())
library("openxlsx")
setwd("C:\\Users\\mbounthavong\\Dropbox\\UCSD Folder\\Courses\\SPPS 208\\Winter 2023\\Stats project\\Data sets\\Ivermectin RCT")
data1 <- read.csv(Ivermectin_Study_Final_Data_Sheet.csv)
data1 <- read.csv(Ivermectin_Study_Final_Data_Sheet.csv , header = TRUE)
?read.csv
data1 <- read.csv(Ivermectin_Study_Final_Data_Sheet.csv, header = TRUE, sep = “,”)
setwd("C:\\Users\\mbounthavong\\Dropbox\\UCSD Folder\\Courses\\SPPS 208\\Winter 2023\\Stats project\\Data sets\\Ivermectin RCT")
library(readxl)
Ivermectin_Study_Final_Data_Sheet <- read_excel("Ivermectin_Study_Final_Data_Sheet.xlsx")
View(Ivermectin_Study_Final_Data_Sheet)
data1 <- Ivermectin_Study_Final_Data_Sheet
data1
view(data1)
View(data1)
data2 <- data1[-c(78, 116:118), ]
data2
View(data2)
data2$age2 <- as.numeric(data2$age)
typeof(data2@age2)
typeof(data2$age2)
data1 <- read.csv2(Ivermectin_Study_Final_Data_Sheet.csv, header = TRUE, sep = “,”)
data1 <- read.csv("Ivermectin_Study_Final_Data_Sheet.csv", header = TRUE, sep = “,”)
data1 <- read.csv("Ivermectin_Study_Final_Data_Sheet.csv", header = TRUE)
data1
data2 <- data1[-c(78, 116:118), ]
data2$age2 <- as.numeric(data2$age)
typeof(data2$age2)
View(data2)
t.test(data$age2 ~ data2$Group.A..B)
?t.test
t.test(data$age2, data2$Group.A..B)
t.test(age2 ~ Group.A..B, data = data2)
